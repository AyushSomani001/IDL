{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b5173",
   "metadata": {
    "id": "26394f54"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from shutil import copyfile\n",
    "from glob import glob\n",
    "from json import load, dump\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D,\\\n",
    "    Activation\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from os.path import basename\n",
    "from time import time\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39231126",
   "metadata": {
    "id": "b618d94b",
    "outputId": "b0212dcf-d91e-40b9-ec7e-87a44667bdfc"
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] loading Fashion MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "# one-hot encode the training and testing labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "# initialize the label names\n",
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773ada6",
   "metadata": {
    "id": "d9a37e21"
   },
   "outputs": [],
   "source": [
    "WIDTH = 28\n",
    "HEIGHT = 28\n",
    "EPOCHS = 1000\n",
    "PATIENCE = 50\n",
    "LR = 0.001\n",
    "NUM_CLASS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852420db",
   "metadata": {
    "id": "04a16e90"
   },
   "outputs": [],
   "source": [
    "filters=10\n",
    "NUM_CLASS=10\n",
    "tiny_vgg = Sequential([\n",
    "    Conv2D(filters, (3, 3), input_shape=(28, 28, 1), name='conv_1_1'),\n",
    "    Activation('relu', name='relu_1_1'),\n",
    "    Conv2D(filters, (3, 3), name='conv_1_2'),\n",
    "    Activation('relu', name='relu_1_2'),\n",
    "    MaxPool2D((2, 2), name='max_pool_1'),\n",
    "\n",
    "    Conv2D(filters, (3, 3), name='conv_2_1'),\n",
    "    Activation('relu', name='relu_2_1'),\n",
    "    Conv2D(filters, (3, 3), name='conv_2_2'),\n",
    "    Activation('relu', name='relu_2_2'),\n",
    "    MaxPool2D((2, 2), name='max_pool_2'),\n",
    "\n",
    "    Flatten(name='flatten'),\n",
    "    Dense(NUM_CLASS, activation='softmax', name='output')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06891a2",
   "metadata": {
    "id": "f68a04c4"
   },
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LR)\n",
    "\n",
    "train_mean_loss = tf.keras.metrics.Mean(name='train_mean_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "vali_mean_loss = tf.keras.metrics.Mean(name='vali_mean_loss')\n",
    "vali_accuracy = tf.keras.metrics.CategoricalAccuracy(name='vali_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4456631",
   "metadata": {
    "id": "420247c7"
   },
   "outputs": [],
   "source": [
    "def train_step(image_batch, label_batch):\n",
    "   with tf.device('/GPU:0'):  \n",
    "    with tf.GradientTape() as tape:\n",
    "        # Predict\n",
    "        predictions = tiny_vgg(image_batch)\n",
    "\n",
    "        # Update gradient\n",
    "        loss = loss_object(label_batch, predictions)\n",
    "        gradients = tape.gradient(loss, tiny_vgg.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, tiny_vgg.trainable_variables))\n",
    "\n",
    "        train_mean_loss(loss)\n",
    "        train_accuracy(label_batch, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aafd24",
   "metadata": {
    "id": "2bf495c0",
    "outputId": "8ea47223-6998-43b9-84d1-ae9986c2df5e"
   },
   "outputs": [],
   "source": [
    "def create_batch(trainx,trainy,batch_size):\n",
    "  dataset=[]\n",
    "  for i in range(len(trainy)//batch_size ):\n",
    "    \n",
    "    if((i+1)*32<len(trainy)):\n",
    "      trainX=np.array(trainx[i*32:(i+1)*32])\n",
    "      trainY=np.array(trainy[i*32:(i+1)*32])\n",
    "    else:\n",
    "      trainX=np.array(trainx[i*32:])\n",
    "      trainY=np.array(trainy[i*32:])\n",
    "    dataset.append((trainX,trainY))\n",
    "  return dataset\n",
    "train_dataset=create_batch(trainX,trainY,BATCH_SIZE)\n",
    "\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518e9d3",
   "metadata": {
    "id": "cc0307b1",
    "outputId": "7f4f0dd2-7195-4dc5-dee8-192f08fd18fe"
   },
   "outputs": [],
   "source": [
    "# rain_dataset[0][1].shape\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train\n",
    "    for image_batch, label_batch in train_dataset:\n",
    "        \n",
    "        \n",
    "        train_step(image_batch, label_batch)\n",
    "\n",
    "    \n",
    "    \n",
    "    template = 'epoch: {}, train loss: {:.4f}, train accuracy: {:.4f}, '\n",
    "    \n",
    "    print(template.format(epoch + 1,\n",
    "                          train_mean_loss.result(),\n",
    "                          train_accuracy.result() * 100))\n",
    "                          \n",
    "\n",
    "   \n",
    "    \n",
    "    train_mean_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "tiny_vgg.save('trained_tiny_vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16736a1",
   "metadata": {
    "id": "9a580121",
    "outputId": "b313159f-c42b-4106-ca8d-380eedd8ba12"
   },
   "outputs": [],
   "source": [
    "tiny_vgg.load_weights(\"trained_tiny_vgg.h5\")\n",
    "test_dataset = create_batch(testX,testY,BATCH_SIZE)\n",
    "test_mean_loss = tf.keras.metrics.Mean(name='test_mean_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "def test_step(image_batch, label_batch):\n",
    "    predictions = tiny_vgg(image_batch)\n",
    "    test_loss = loss_object(label_batch, predictions)\n",
    "\n",
    "    test_mean_loss(test_loss)\n",
    "    test_accuracy(label_batch, predictions)\n",
    "for image_batch, label_batch in test_dataset:\n",
    "    test_step(image_batch, label_batch)\n",
    "template = '\\ntest loss: {:.4f}, test accuracy: {:.4f}'\n",
    "print(template.format(test_mean_loss.result(),\n",
    "                      test_accuracy.result() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01322739",
   "metadata": {
    "id": "c4c6a05a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_h5_to_json(model_h5_file, model_json_file):\n",
    "    \"\"\"\n",
    "    Helper function to convert tf2 stored model h5 file to a customized json\n",
    "    format.\n",
    "    Args:\n",
    "        model_h5_file(string): filename of the stored h5 file\n",
    "        model_json_file(string): filename of the output json file\n",
    "    \"\"\"\n",
    "\n",
    "    model = tf.keras.models.load_model(model_h5_file)\n",
    "    json_dict = {}\n",
    "\n",
    "    for l in model.layers:\n",
    "        json_dict[l.name] = {\n",
    "            'input_shape': l.input_shape[1:],\n",
    "            'output_shape': l.output_shape[1:],\n",
    "            'num_neurons': l.output_shape[-1]\n",
    "        }\n",
    "\n",
    "        if 'conv' in l.name:\n",
    "            all_weights = l.weights[0]\n",
    "            neuron_weights = []\n",
    "\n",
    "            # Iterate through neurons in that layer\n",
    "            for n in range(all_weights.shape[3]):\n",
    "                cur_neuron_dict = {}\n",
    "                cur_neuron_dict['bias'] = l.bias.numpy()[n].item()\n",
    "\n",
    "                # Get the current weights\n",
    "                cur_weights = all_weights[:, :, :, n].numpy().astype(float)\n",
    "\n",
    "                # Reshape the weights from (height, width, input_c) to\n",
    "                # (input_c, height, width)\n",
    "                cur_weights = cur_weights.transpose((2, 0, 1)).tolist()\n",
    "                cur_neuron_dict['weights'] = cur_weights\n",
    "\n",
    "                neuron_weights.append(cur_neuron_dict)\n",
    "\n",
    "            json_dict[l.name]['weights'] = neuron_weights\n",
    "\n",
    "        elif 'output' in l.name:\n",
    "            all_weights = l.weights[0]\n",
    "            neuron_weights = []\n",
    "\n",
    "            # Iterate through neurons in that layer\n",
    "            for n in range(all_weights.shape[1]):\n",
    "                cur_neuron_dict = {}\n",
    "                cur_neuron_dict['bias'] = l.bias.numpy()[n].item()\n",
    "\n",
    "                # Get the current weights\n",
    "                cur_weights = all_weights[:, n].numpy().astype(float).tolist()\n",
    "                cur_neuron_dict['weights'] = cur_weights\n",
    "\n",
    "                neuron_weights.append(cur_neuron_dict)\n",
    "\n",
    "            json_dict[l.name]['weights'] = neuron_weights\n",
    "\n",
    "    dump(json_dict, open(model_json_file, 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9341d58",
   "metadata": {
    "id": "4efff9f4",
    "outputId": "a2970d64-4fa8-46f3-a67c-421d63beb4ba"
   },
   "outputs": [],
   "source": [
    "convert_h5_to_json(\"trained_tiny_vgg.h5\", \"model1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975263c0",
   "metadata": {
    "id": "b0abec80",
    "outputId": "1b2ff4b5-201b-40ae-edd9-114583cb1d26"
   },
   "outputs": [],
   "source": [
    "my_model = tf.keras.models.load_model('trained_tiny_vgg.h5')\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35441dec",
   "metadata": {
    "id": "e1b48211"
   },
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in my_model.layers[:12]] # Extracts the outputs of the top 12 layers\n",
    "activation_model = Model(inputs=my_model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2997ab",
   "metadata": {
    "id": "6af4f897"
   },
   "outputs": [],
   "source": [
    "img_tensor=trainX[1].reshape(-1,28,28,1)\n",
    "\n",
    "activations = activation_model.predict(img_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637e3aa",
   "metadata": {
    "id": "24acd16e",
    "outputId": "4ae1f5f1-053e-43e1-ff3e-fc3f24d2a8e4"
   },
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for layer in my_model.layers[:-2]:\n",
    "    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
    "    \n",
    "images_per_row = 10\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
    "    n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
    "    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
    "    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, # Displays the grid\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='Greys')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn_explainer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
