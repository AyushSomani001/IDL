{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Google Colaboratory (if needed)\n",
    "Set the variable `colab` to `True` if you are using this notebook from Google Colaboratory, else set it to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False  # Set to true if working on Google Colaboratory\n",
    "\n",
    "if colab:\n",
    "    # Mount your Google Drive for storage\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Save to, and access files from, your Google Drive if using Colaboratory \n",
    "    ROOT_DIR = '/content/drive/MyDrive/IDL'\n",
    "    \n",
    "    # Fetch the git repository\n",
    "    !git clone https://github.com/AyushSomani001/IDL {ROOT_DIR}\n",
    "\n",
    "else:\n",
    "     ROOT_DIR = '../..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Cvs94Cf77x-"
   },
   "outputs": [],
   "source": [
    "reqs_file = f'{ROOT_DIR}/requirements.txt'\n",
    "!pip install -r {reqs_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrOArAWb93fF"
   },
   "source": [
    "PyTorch is a popular open-source machine learning framework used for building deep learning models, while CIFAR-10 is a dataset of 60,000 32x32 color images in 10 classes, with 6,000 images per class. The dataset is often used as a benchmark for image classification tasks.\n",
    "\n",
    "<small> &diams; Note: The code and documentation are designed to be accessible and understandable to people who are new to machine learning and deep learning. It may be a good option for people who are just starting out with PyTorch and want to learn how to build an image classifier. </small>\n",
    "\n",
    "<img alt=\"A photo of a man on an elephant with an ML-generated overlay showing objects in the frame\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/54/DenseCap_%28Johnson_et_al.%2C_2016%29.png\" width=800px/> \n",
    "<caption>Figure shows the problem of dense captioning, where a computer detects objects in images and describes them in natural language.</caption>\n",
    "\n",
    "\n",
    "\n",
    "##### # Image Source: <cite><a href=\"https://cs.stanford.edu/people/karpathy/densecap/\">Densecap: Fully convolutional localization networks for dense captioning</a> by Johnson, Justin, Andrej Karpathy, and Li Fei-Fei. Proceedings of the IEEE conference on computer vision and pattern recognition 2016.</cite>\n",
    "\n",
    "<hr>\n",
    "\n",
    "If we want to build a ML model that can identify objects in images, we can create an image classifier using a deep neural network (DNN). This involves training the network on a large dataset of labeled images, which enables it to recognize patterns and features that correspond to different objects.\n",
    "\n",
    "For our particular task, we're interested in building an image classifier that can identify 10 different types of objects, including planes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. To do this, we'll start by downloading an appropriate dataset that includes examples of each object type.\n",
    "\n",
    "Once we have our dataset, we'll use a tool like PyTorch to train our neural network, tuning its parameters and architecture until it's able to accurately classify the objects in the images. Finally, we'll evaluate the performance of our model to see how well it's able to generalize to new, unseen images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTkTQP3l97PJ"
   },
   "source": [
    "## Step 1: Download a dataset and preview images\n",
    "\n",
    "The accuracy and effectiveness of a machine learning model is heavily dependent on the quality and quantity of data it is trained on. In order to build an accurate image classifier, we need a large dataset of high-quality images that are representative of the types of objects we want our model to recognize.\n",
    "\n",
    "For this project, we will be using the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) dataset, which contains 60,000 labeled images in 10 different classes. This dataset is commonly used as a benchmark for image classification tasks and is widely recognized as a high-quality dataset for training machine learning models.\n",
    "\n",
    "To get started, we can download the CIFAR-10 dataset using the `torchvision` library and preview a few sample images to get an idea of what the data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "5lVEJRqi9HSo",
    "outputId": "808f9f95-d7ab-422e-d881-79880c2e6dbe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set batch size and apply transformation\n",
    "batch_size = 10\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Download the CIFAR-10 dataset to ./data\n",
    "print(\"Downloading Training Data...\")\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "print(\"Downloading Testing Data...\")\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define classes for image recognition\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Get a batch of images and labels from training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Plot images and their labels\n",
    "for i in range(batch_size):\n",
    "    # Add new subplot\n",
    "    plt.subplot(2, int(batch_size/2), i + 1)\n",
    "    # Plot the image\n",
    "    img = images[i]\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    # Add the image's label\n",
    "    plt.title(classes[labels[i]])\n",
    "\n",
    "plt.suptitle('Preview of Training Data', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRcLjXFSHL5L"
   },
   "source": [
    "We begin by downloading the CIFAR-10 dataset, which contains 60,000 images of various objects. The dataset is divided into a training set and a testing set. We use the `torchvision` library to download and prepare the data. The data is transformed by scaling the pixel values and normalizing them to a range of -1 to 1.\n",
    "\n",
    "We then define a `batch_size` of 10 and create `DataLoader` objects for both the training and testing sets. These objects help us iterate over the data in batches during the training process.\n",
    "\n",
    "To get a better understanding of the data we're working with, we use `matplotlib` to create a visualization of a handful of images from the training set. We extract a batch of images using the `iter()` method and then loop through each image, adding it to a new subplot in our plot. We also add the corresponding label to each subplot to help us identify the object in the image.\n",
    "\n",
    "Finally, we use `plt.show()` to display the plot of our training data preview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU-nqbly9Rwr"
   },
   "source": [
    "# Step 2: Configure the neural network\n",
    "\n",
    "Having obtained our dataset, the next step is to configure a neural network for `PyTorch`. The neural network will be responsible for converting an image into a corresponding description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBB9gCkE9SFB",
    "outputId": "90bd69a5-8f9b-454a-923f-0730c3aafdfe"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))    # Apply convolution and pooling layers\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)       # Flatten the tensor before passing it to the fully connected layers\n",
    "        x = F.relu(self.fc1(x))       # Apply activation function to the output of each fully connected layer\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the neural network        \n",
    "net = Net()\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(\"The neural network has been defined and is ready for training.!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g395JaAL9UjE"
   },
   "source": [
    "# Step 3: Train the network and save model\n",
    "\n",
    "PyTorch trains our network by adjusting its parameters and evaluating its performance against our labelled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBAyAgsU9U2T",
    "outputId": "84a7b0fe-82f0-4d83-f928-66662a013a18"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 5\n",
    "print(\"Training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(trainloader, desc=f\"Epoch {epoch + 1} of {EPOCHS}\", leave=True, ncols=80)):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Save our trained model\n",
    "PATH = f'{ROOT_DIR}/Assignments/Task1_Image-Classifer/cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCPCCZS89YA-"
   },
   "source": [
    "# Step 4: Test the trained model\n",
    "\n",
    "It's time to evaluate our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "bh7Hp9Ms9XR0",
    "outputId": "fb5e47b6-41af-4c18-a56d-74eae287acb4"
   },
   "outputs": [],
   "source": [
    "# Pick random photos from training set\n",
    "if dataiter == None:\n",
    "    dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Load our model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# Analyze images\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Show results\n",
    "for i in range(batch_size):\n",
    "    # Add new subplot\n",
    "    plt.subplot(2, int(batch_size/2), i + 1)\n",
    "    # Plot the image\n",
    "    img = images[i]\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    # Add the image's label\n",
    "    color = \"green\"\n",
    "    label = classes[predicted[i]]\n",
    "    if classes[labels[i]] != classes[predicted[i]]:\n",
    "        color = \"red\"\n",
    "        label = \"(\" + label + \")\"\n",
    "    plt.title(label, color=color)\n",
    "\n",
    "plt.suptitle('Objects Found by Model', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdzFDbse9a4A"
   },
   "source": [
    "# Step 5: Evaluate model accuracy\n",
    "\n",
    "To conclude, we will evaluate the overall performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a8_kK8z9bM1",
    "outputId": "4251a437-d96a-4336-ddeb-6e73c80f2b3f"
   },
   "outputs": [],
   "source": [
    "# Record the number of correct predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "#Use the trained network to make predictions on the test dataset\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # Track the number of correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "# Print accuracy statistics for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVB0Fp5TLg9D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
